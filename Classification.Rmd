---
title: "Classification"
output: html_notebook
---

```{r}
library(dplyr)
library(textclean)
library(ngram)
library(caret)
library(stringr)
```


### read data from mercur mooc
```{r}
files = list.files("/home/doberstein/Dropbox/D/uni/CRIWG/data/Classified Sequences/all_classified_sequences", full.names = TRUE)
data_files=lapply(files, read.table, sep=";", as.is = T)
for (i in 1:length(data_files)){data_files[[i]]<-cbind(data_files[[i]],files[i])}
data <- do.call("rbind", data_files) 
colnames(data)[c(1,2,3,4,5,6,7,8,9,10,11)]<-c("ID", "user", "type","start", "end", "period", "duration", "textChange", "content", "class", "filename")
#allData <- data
data <- data %>% 
  filter(!class %in% c("None")) %>% 
  filter(!user %in% c("user"))

# fix filenames
data$filename <- gsub("/home/doberstein/Dropbox/D/uni/CRIWG/data/Classified Sequences/all_classified_sequences/", "", data$filename)


# data <- filter(data, !user == "user") %>% 
#   filter(!class %in% c("start", "None"))

#/home/doberstein/Dropbox/D/Masterarbeit/R

# newTimeData <- read.csv2(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/completeIdleData.csv", header = T, sep = ",")
# newToolData <-  read.csv(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/toolData.csv", header = T)
# newPosData <-  read.csv(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/posData.csv", header = T)
# newUserChangeData <-  read.csv(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/userChangeData.csv", header = T)
# newTextChangeData <-  read.csv2(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/textChangeData.csv", header = T, sep = ";")
# 
# 
# data_ordered <- data %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# newTimeData_ordered <- newTimeData %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# newToolData_ordered <- newToolData %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# newPosData_ordered <- newPosData %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# newUserChangeData_ordered <- newUserChangeData %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# newTextChangeData_ordered <- newTextChangeData %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# 
# data_ordered$idleSince <- newTimeData_ordered$idleSince
# data_ordered$toolChange <- newToolData_ordered$toolChange
# data_ordered$position <- newPosData_ordered$position
# data_ordered$userChange <- newUserChangeData_ordered$userChange
# data_ordered$textChange <- newTextChangeData_ordered$textChange

```

#TODO
reproduce feature calculation (without lists)
  position            done
  idle since          done (take start - lag(start) for idle time, since activity timeframes might overlap -> negative values)
  toolchange          done
  user change         done
  fix text change?    done

```{r}
# add position in sequence
data_features <- data %>% 
  group_by(filename) %>% 
  mutate(position = row_number()-1)

# clean content
cleanFun <- function(htmlString) {
  htmlString <- gsub("<.*?>", " ", htmlString)
  htmlString <- gsub("\n", " ", htmlString, fixed = T)
  htmlString <- gsub("\\n", " ", htmlString, fixed = T)
  htmlString
}

#data_features$cleaned_con <- cleanFun(data_features$content)

data_features <- data_features %>% 
  group_by(filename) %>% 
  # add time since last activity
  mutate(idle_since = as.numeric(start) - lag(as.numeric(start))) %>% 
  # add tool change
  mutate(tool_change = ifelse(type == lag(type), F, T)) %>% 
  # add user change
  mutate(user_change = ifelse(user == lag(user), F, T)) %>% 
  # clean content
  mutate(content_cleaned = cleanFun(content)) %>% 
  # add wordcount
  rowwise() %>% 
  mutate(wordcount = wordcount(content_cleaned))

# correct text change

forum <- data_features %>% 
  filter(type == "forum")

etherpad <- data_features %>% 
  filter(type == "etherpad")

# calculate wordcount as diff between wordcount of current and last contribution
etherpad <- etherpad %>% 
  group_by(filename) %>% 
  mutate(wordcount_fixed = wordcount - lag(wordcount))

# fix negative wordcounts
etherpad$wordcount_fixed[etherpad$wordcount_fixed < 0] <- 0
# fix wordcounts for first contributions
etherpad$wordcount_fixed[is.na(etherpad$wordcount_fixed)] <- etherpad$wordcount[is.na(etherpad$wordcount_fixed)]

etherpad$wordcount <- etherpad$wordcount_fixed
etherpad <- etherpad %>% 
  subset(select = -wordcount_fixed)

forum$wordcount <- as.numeric(forum$wordcount)
etherpad$wordcount <- as.numeric(etherpad$wordcount)


typeof(forum$wordcount)
typeof(etherpad$wordcount)

#all_data <- rbind(forum, etherpad)
all_data <- bind_rows(forum, etherpad) %>% 
  group_by(filename) %>% 
  dplyr::arrange(start, .by_group = T)  

all_data <- all_data %>% 
  filter(!class == "start")

# fix period to be numerical
all_data$period <- as.numeric(all_data$period)



```

###Splitting data
```{r}
set.seed(42)
svmIndex <- createDataPartition(y = all_data$class, p = 0.7, list = F)

svmTrain <- all_data[svmIndex,]
svmTest <- all_data[-svmIndex,]


```


###Training Model Random Forest (training and test data)
```{r}

names(all_data)
rf_fit <- train(class ~ wordcount + type + tool_c + idle1 + pos1 + period + user_c, data = svmTrain, method = "ranger")
# saving and reading model
# saveRDS(rf_fit, "C:/Users/doberstein/Dropbox/D/Masterarbeit/datasets/model.rds")
# new_model <- readRDS("C:/Users/doberstein/Dropbox/D/Masterarbeit/datasets/model.rds")
prediction_rf_fit <- predict(rf_fit, svmTest)
svmTest$class_factor <- as.factor(svmTest$class)
svmTest$class
svmTest$class_factor
confusionMatrix(prediction_rf_fit, svmTest$class_factor, mode = "everything")
```

## checking dataformat for both datasets
```{r}
# wordcount     
class(all_data$wordcount)
class(t1_t2_t3_sequences$wordcount)

# type     
class(all_data$type)
class(t1_t2_t3_sequences$type)

# tool_change   
class(all_data$tool_change)
class(t1_t2_t3_sequences$tool_change)

# idle_since    
class(all_data$idle_since)
class(t1_t2_t3_sequences$idle_since)

# position    
class(all_data$position)
class(t1_t2_t3_sequences$position)

# period      
class(all_data$period)
class(t1_t2_t3_sequences$period)

# user_change   
class(all_data$user_change)
class(t1_t2_t3_sequences$user_change)

```



###Training model on complete dataset
```{r}
# train model
rf_fit <- train(class ~ wordcount + type + tool_change + idle_since + position + period + user_change, data = all_data, method = "ranger")

# read ikarion dataset
t1_t2_t3_sequences <- read.csv2("/home/doberstein/Dropbox/D/uni/IKARion/CVK MOOC - WS18_19/analysis/t1_t2_t3_activities_with_start.csv", stringsAsFactors = F) %>% 
  subset(select=-c(X, class)) # %>% 
  #filter(!type == "start")
  

#etherpad$wordcount_fixed[etherpad$wordcount_fixed < 0] <- -1
t1_t2_t3_sequences$type[t1_t2_t3_sequences$type == "wiki"] <- "etherpad"

# calculate features
# wordcount     done
# type          done
# tool_change   done
# idle_since    done
# position      done
# period        done
# user_change   done

# add position in sequence; 
t1_t2_t3_sequences <- t1_t2_t3_sequences %>% 
  group_by(group_id) %>% 
  mutate(position = row_number()-1)

t1_t2_t3_sequences <- t1_t2_t3_sequences %>% 
  group_by(group_id) %>% 
  # add time since last activity
  #mutate(idle_since = as.numeric(start) - lag(as.numeric(start))) %>% 
  # add tool change
  mutate(tool_change = ifelse(type == lag(type), F, T)) %>% 
  # add user change
  mutate(user_change = ifelse(user_id == lag(user_id), F, T)) %>% 
  mutate(idle_since = as.numeric(timestamp) - lag(as.numeric(timestamp)))

# delete start activities
t1_t2_t3_sequences <- t1_t2_t3_sequences %>% 
  filter(!type == "start")


# # fix NA values for tool_change and user_change
#   t1_t2_t3_sequences$tool_change[is.na(t1_t2_t3_sequences$tool_change)] <- F  
#   t1_t2_t3_sequences$user_change[is.na(t1_t2_t3_sequences$user_change)] <- F  

# etherpad$wordcount_fixed[is.na(etherpad$wordcount_fixed)] <- etherpad$wordcount[is.na(etherpad$wordcount_fixed)]


# t1_t2_t3_sequences <- t1_t2_t3_sequences %>% 
#   group_by(group_id) %>% 
#   # add time since last activity
#   mutate(idle_since = as.numeric(start) - lag(as.numeric(start))) %>% 
#   # add tool change
#   mutate(tool_change = ifelse(type == lag(type), F, T)) %>% 
#   # add user change
#   mutate(user_change = ifelse(user == lag(user), F, T)) %>% 
  

```

# classsify ikarion data
```{r}
prediction_t1_t2_t3 <- predict(rf_fit, t1_t2_t3_sequences)

t1_t2_t3_sequences$predicted_class <- prediction_t1_t2_t3

```

check classification results
```{r}
i <<- 1
```

```{r}
t1_t2_t3_sequences[i,]$content
t1_t2_t3_sequences[i,]$predicted_class
i <<- i+1

```




# ```{r}
# check_classification <- function(df) {
#   browser()
#   for (row in )
#   i = 1
#   print(df[i,]$content)
#   print(df[i,]$predicted_class)
#   i = i+1
# }
# 
# by(t1_t2_t3_sequences, 1:nrow(t1_t2_t3_sequences), function(row) check_classification())
# 
# check_classification(t1_t2_t3_sequences)
# ```





# NLP analysis
detect prospetive / retrospective character of a message by analyzing the tense of the message using nlp
```{r}

# find all strings that were replaced with "__"
all_strings <- paste(data_features$content_cleaned, collapse = " ")

replaced_values <- grep("__", all_strings, value = T)

strings <- str_extract(all_strings, "__", simplify = T)

splitted <- strsplit(all_strings, " ")


a <- grep("__", all_strings)
 ```





# checking
```{r}
newTimeData <- read.csv2(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/completeIdleData.csv", header = T, sep = ",")

g8 <- data %>% 
  filter(filename == "Gruppe soziale Pr√§senz g8 classified.csv")

t_toolc <- data_features %>% 
  subset(select = c(filename, pos1, type, tool_c))

t_userc <- data_features %>% 
  subset(select = c(filename, type, user, user_c))

# devide dataframe into wiki / forum
# join and test order

forum <- data %>% 
  filter(type == "forum")

etherpad <- data %>% 
  filter(type == "etherpad")

all_data <- rbind(forum, etherpad) %>% 
  group_by(filename) %>% 
  dplyr::arrange(start, .by_group = T)  

t1 <- data_features[487,]$content_cleaned

etherpad$wordcount_fixed[etherpad$wordcount_fixed < 0] <- -1


task1_changing_user_activity_count$norm_rank[is.nan(task1_changing_user_activity_count$norm_rank)] <- 0

etherpad[!is.na(etherpad$wordcount_fixed == 0)]$wordcount_fixed <- "haha"

etherpad[etherpad$wordcount_fixed < 0,]$wordcount_fixed <- 0

all_data$start == data_features$start

svmTest$class

class(data_features[2,]$start)

class(t1_t2_t3_sequences[2,]$timestamp)

class(all_data[2,]$period)

t1 <- all_data
t1$per2 <- as.numeric(t1$period)
class(t1$period)
class(t1$per2)
class(t1_t2_t3_sequences$period)

```





