---
title: "Classification"
output: html_notebook
---

```{r}
library(dplyr)
library(textclean)
library(ngram)
library(caret)
library(stringr)
```


### read data from mercur mooc
```{r}
files = list.files("/home/doberstein/Dropbox/D/uni/CRIWG/data/Classified Sequences/all_classified_sequences", full.names = TRUE)
data_files=lapply(files, read.table, sep=";", as.is = T)
for (i in 1:length(data_files)){data_files[[i]]<-cbind(data_files[[i]],files[i])}
data <- do.call("rbind", data_files) 
colnames(data)[c(1,2,3,4,5,6,7,8,9,10,11)]<-c("ID", "user", "type","start", "end", "period", "duration", "textChange", "content", "class", "filename")
#allData <- data
data <- data %>% 
  filter(!class %in% c("None")) %>% 
  filter(!user %in% c("user"))

# fix filenames
data$filename <- gsub("/home/doberstein/Dropbox/D/uni/CRIWG/data/Classified Sequences/all_classified_sequences/", "", data$filename)


# data <- filter(data, !user == "user") %>% 
#   filter(!class %in% c("start", "None"))

#/home/doberstein/Dropbox/D/Masterarbeit/R

# newTimeData <- read.csv2(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/completeIdleData.csv", header = T, sep = ",")
# newToolData <-  read.csv(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/toolData.csv", header = T)
# newPosData <-  read.csv(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/posData.csv", header = T)
# newUserChangeData <-  read.csv(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/userChangeData.csv", header = T)
# newTextChangeData <-  read.csv2(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/textChangeData.csv", header = T, sep = ";")
# 
# 
# data_ordered <- data %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# newTimeData_ordered <- newTimeData %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# newToolData_ordered <- newToolData %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# newPosData_ordered <- newPosData %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# newUserChangeData_ordered <- newUserChangeData %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# newTextChangeData_ordered <- newTextChangeData %>% 
#   group_by(filename) %>% 
#   group_by(start, add = T) %>% 
#   arrange(filename, .by_group = T)
# 
# 
# data_ordered$idleSince <- newTimeData_ordered$idleSince
# data_ordered$toolChange <- newToolData_ordered$toolChange
# data_ordered$position <- newPosData_ordered$position
# data_ordered$userChange <- newUserChangeData_ordered$userChange
# data_ordered$textChange <- newTextChangeData_ordered$textChange

```

#TODO
reproduce feature calculation (without lists)
  position            done
  idle since          done (take start - lag(start) for idle time, since activity timeframes might overlap -> negative values)
  toolchange          done
  user change         done
  fix text change?    done

```{r}
# add position in sequence
data_features <- data %>% 
  group_by(filename) %>% 
  mutate(pos1 = row_number()-1)

# clean content
cleanFun <- function(htmlString) {
  htmlString <- gsub("<.*?>", " ", htmlString)
  htmlString <- gsub("\n", " ", htmlString, fixed = T)
  htmlString <- gsub("\\n", " ", htmlString, fixed = T)
  htmlString
}

#data_features$cleaned_con <- cleanFun(data_features$content)

data_features <- data_features %>% 
  group_by(filename) %>% 
  # add time since last activity
  mutate(idle1 = as.numeric(start) - lag(as.numeric(start))) %>% 
  # add tool change
  mutate(tool_c = ifelse(type == lag(type), F, T)) %>% 
  # add user change
  mutate(user_c = ifelse(user == lag(user), F, T)) %>% 
  # clean content
  mutate(content_cleaned = cleanFun(content)) %>% 
  # add wordcount
  rowwise() %>% 
  mutate(wordcount = wordcount(content_cleaned))

# correct text change

forum <- data_features %>% 
  filter(type == "forum")

etherpad <- data_features %>% 
  filter(type == "etherpad")

# calculate wordcount as diff between wordcount of current and last contribution
etherpad <- etherpad %>% 
  group_by(filename) %>% 
  mutate(wordcount_fixed = wordcount - lag(wordcount))

# fix negative wordcounts
etherpad$wordcount_fixed[etherpad$wordcount_fixed < 0] <- 0
# fix wordcounts for first contributions
etherpad$wordcount_fixed[is.na(etherpad$wordcount_fixed)] <- etherpad$wordcount[is.na(etherpad$wordcount_fixed)]

etherpad$wordcount <- etherpad$wordcount_fixed
etherpad <- etherpad %>% 
  subset(select = -wordcount_fixed)

forum$wordcount <- as.numeric(forum$wordcount)
etherpad$wordcount <- as.numeric(etherpad$wordcount)


typeof(forum$wordcount)
typeof(etherpad$wordcount)

#all_data <- rbind(forum, etherpad)
all_data <- bind_rows(forum, etherpad) %>% 
  group_by(filename) %>% 
  dplyr::arrange(start, .by_group = T)  

all_data <- all_data %>% 
  filter(!class == "start")


```

###Splitting data
```{r}
set.seed(42)
svmIndex <- createDataPartition(y = all_data$class, p = 0.7, list = F)

svmTrain <- all_data[svmIndex,]
svmTest <- all_data[-svmIndex,]


```


###Training Model Random Forest
```{r}

names(all_data)
rf_fit <- train(class ~ wordcount + type + tool_c + idle1 + pos1 + period + user_c, data = svmTrain, method = "ranger")

# saving and reading model
# saveRDS(rf_fit, "C:/Users/doberstein/Dropbox/D/Masterarbeit/datasets/model.rds")
# new_model <- readRDS("C:/Users/doberstein/Dropbox/D/Masterarbeit/datasets/model.rds")


prediction_rf_fit <- predict(rf_fit, svmTest)

svmTest$class_factor <- as.factor(svmTest$class)

svmTest$class
svmTest$class_factor


confusionMatrix(prediction_rf_fit, svmTest$class_factor, mode = "everything")
```

# NLP analysis
detect prospetive / retrospective character of a message by analyzing the tense of the message using nlp
```{r}

# find all strings that were replaced with "__"
all_strings <- paste(data_features$content_cleaned, collapse = " ")

replaced_values <- grep("__", all_strings, value = T)

strings <- str_extract(all_strings, "__", simplify = T)

splitted <- strsplit(all_strings, " ")


a <- grep("__", all_strings)
 ```





# checking
```{r}
newTimeData <- read.csv2(file = "/home/doberstein/Dropbox/D/Masterarbeit/R/completeIdleData.csv", header = T, sep = ",")

g8 <- data %>% 
  filter(filename == "Gruppe soziale Pr√§senz g8 classified.csv")

t_toolc <- data_features %>% 
  subset(select = c(filename, pos1, type, tool_c))

t_userc <- data_features %>% 
  subset(select = c(filename, type, user, user_c))

# devide dataframe into wiki / forum
# join and test order

forum <- data %>% 
  filter(type == "forum")

etherpad <- data %>% 
  filter(type == "etherpad")

all_data <- rbind(forum, etherpad) %>% 
  group_by(filename) %>% 
  dplyr::arrange(start, .by_group = T)  

t1 <- data_features[487,]$content_cleaned

etherpad$wordcount_fixed[etherpad$wordcount_fixed < 0] <- -1


task1_changing_user_activity_count$norm_rank[is.nan(task1_changing_user_activity_count$norm_rank)] <- 0

etherpad[!is.na(etherpad$wordcount_fixed == 0)]$wordcount_fixed <- "haha"

etherpad[etherpad$wordcount_fixed < 0,]$wordcount_fixed <- 0

all_data$start == data_features$start

# filter start activities



svmTest$class

```





