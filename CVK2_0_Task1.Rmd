---
title: "CVK 2.0 Task 1"
output: html_notebook
---

```{r}
source("setup.R")
source("CVK2-util.R")
```

###TODO for new task:
####read new files
####adjust condition information
####adjust start date (task_begin <- as.Date(...))

### READ DATA, GENERATE DATASET
```{r}
### ONCE ###
# complete final models with content for each condition
data_S <- fromJSON("/home/doberstein/Dropbox/D/uni/IKARion/MCK MOOC - SoSe19/Task 1/Task1_EA1_S_with_content.txt")
data_M <- fromJSON("/home/doberstein/Dropbox/D/uni/IKARion/MCK MOOC - SoSe19/Task 1/Task1_EA1_M_with_content.txt")


### SEQUENCES ###
# unnest sequences from lists to data.frame
sequences_S <- data_S$group_sequences %>%
  unnest()
sequences_M <- data_M$group_sequences %>%
  unnest()

## CLEANING DATASET SINCE THIS TASK WAS LOGGED ON THE THL IKARION SERVER WICH FOR WHATEVER REASON LOGGED SOME ACTIVITIES TWICE ##
## (problem lies with the learning locker which forwards the actions twice)

sequences_S <- sequences_S %>%
  distinct(content, .keep_all = T)

sequences_M <- sequences_M %>%
  distinct(content, .keep_all = T)


#t11 <- distinct(sequences_S, content, .keep_all = T)

# combine all files to a single table
sequences <- bind_rows(list(sequences_S, sequences_M))

write.csv2(sequences, "/home/doberstein/Dropbox/D/uni/IKARion/MCK MOOC - SoSe19/analysis/task1_activities.csv", row.names = F)

### WORK IMBALANCE ###
# extract work imbalances
work_imbalance_S <- data_S$work_imbalance
work_imbalance_M <- data_M$work_imbalance

# combine all files to a single table
work_imbalances <- bind_rows(list(work_imbalance_S, work_imbalance_M))

# adding condition information #
work_imbalances <- MCKaddConditions(work_imbalances)

write.csv2(work_imbalances, "/home/doberstein/Dropbox/D/uni/IKARion/MCK MOOC - SoSe19/analysis/task1_work_imbalances.csv", row.names = F)

### FINAL WIKI weighted wordcounts ###
weighted_wordcount_wiki_S <- data_S$weighted_wiki_wordcount %>%
  unnest()
weighted_wordcount_wiki_M <- data_M$weighted_wiki_wordcount %>%
  unnest()

# combine all files to a single table
weighted_wiki_wordcounts <- bind_rows(list(weighted_wordcount_wiki_S, weighted_wordcount_wiki_M)) %>%
  MCKaddConditions()

write.csv2(weighted_wiki_wordcounts, "/home/doberstein/Dropbox/D/uni/IKARion/MCK MOOC - SoSe19/analysis/task1_weighted_wiki_wordcounts.csv", row.names = F)

### FINAL Forum WORD COUNTS ###
wordcount_share_forum_S <- data_S$weighted_forum_wordcount %>%
  unnest()
wordcount_share_forum_M <- data_M$weighted_forum_wordcount %>%
  unnest()

# combine all files to a single table
forum_shares <- bind_rows(list(wordcount_share_forum_S, wordcount_share_forum_M)) %>%
  MCKaddConditions()

write.csv2(forum_shares, "/home/doberstein/Dropbox/D/uni/IKARion/MCK MOOC - SoSe19/analysis/task1_forum_shares.csv")

# extract groups and users
users_groups_S <- data_S$model_metadata$groups %>%
  unnest()
users_groups_M <- data_M$model_metadata$groups %>%
  unnest()

# combine all files to a single table
groups_and_users <- bind_rows(list(users_groups_S, users_groups_M)) %>%
  subset(select = c("group_id", "name"))
names(groups_and_users)[names(groups_and_users) == 'name'] <- 'user_id'

groups_and_users <- MCKaddConditions(groups_and_users)


write.csv2(groups_and_users, "/home/doberstein/Dropbox/D/uni/IKARion/MCK MOOC - SoSe19/analysis/task1_groups_and_users.csv")
```

